# Blood Pressure Monitoring System

## **Overview**

This project implements a system for real-time monitoring and analysis of blood pressure data using the FHIR (Fast Healthcare Interoperability Resources) standard. It generates, processes, and visualizes blood pressure readings to detect anomalies (e.g., hypertension or hypertensive crisis) and provides a dashboard for analysis. The system leverages Kafka, Elasticsearch, and Kibana to handle data ingestion, storage, and visualization.

---

## **System Architecture**

### **Components**

1. **Data Generation (Producer):**

   - Generates synthetic blood pressure readings in FHIR-compliant JSON format.
   - Sends data to Kafka topics.

2. **Data Processing (Consumer):**

   - Reads messages from Kafka topics.
   - Classifies observations as normal or anomalous based on FHIR-compliant blood pressure categories.
   - Saves normal observations to a local file.
   - Indexes anomalies into Elasticsearch.

3. **Data Visualization (Dashboard):**

   - Uses Kibana to create visualizations and dashboards.
   - Displays distributions, trends, and critical observations.

4. **Infrastructure Configuration (YAML):**

   - A `docker-compose.yml` file is used to configure and manage the Docker containers for Kafka, Elasticsearch, and Kibana.
   - Defines services, ports, and dependencies for seamless integration.

---

## **Project Setup**

### **Prerequisites**

- Docker
- Python (>=3.8)
- Kafka
- Elasticsearch
- Kibana

### **Installation**

1. Clone the repository:

   ```bash
   git clone https://github.com/your-repo/blood-pressure-monitoring.git
   cd blood-pressure-monitoring
   ```

2. Start the Docker containers for Kafka, Elasticsearch, and Kibana:

   ```bash
   docker-compose up
   ```

3. Install Python dependencies:

   ```bash
   pip install -r requirements.txt
   ```

---

## **Usage**

### **1. Start the Kafka Producer**

- Generates FHIR-compliant blood pressure observations and sends them to the Kafka topic.
- Run the producer:

  ```bash
  python src/kafka_producer.py
  ```

### **2. Start the Kafka Consumer**

- Processes incoming messages, classifies observations, and stores them appropriately.
- Run the consumer:

  ```bash
  python src/kafka_consumer.py
  ```

### **3. Access Kibana Dashboard**

- Open Kibana in your browser:
  ```
  http://localhost:5601
  ```
- Create visualizations and dashboards for the indexed anomalies.

---

## **Producer Details**

The Kafka producer is responsible for generating synthetic blood pressure readings in FHIR-compliant JSON format. It performs the following tasks:

- Randomly generates blood pressure values categorized as normal, elevated, hypertension stage 1, stage 2, or hypertensive crisis.
- Serializes the data into JSON format.
- Sends the data to the Kafka topic `fhir_observations`.

**Code Highlights:**

- Uses Python's `kafka.KafkaProducer` for message production.
- Data includes FHIR fields such as `resourceType`, `category`, `code`, and `component`.

---

## **Consumer Details**

The Kafka consumer is responsible for processing the data generated by the producer. It performs the following tasks:

- Reads messages from the Kafka topic `fhir_observations`.
- Classifies each observation based on systolic and diastolic pressure values.
- Saves normal observations to a local file `normal_observations.json`.
- Indexes anomalies into Elasticsearch (`bp_fhir_index`).

**Code Highlights:**

- Uses Python's `kafka.KafkaConsumer` for message consumption.
- Implements a classification function to categorize blood pressure readings.
- Ensures compliance with the FHIR standard.

---

## **Infrastructure Configuration (YAML)**

The `docker-compose.yml` file defines the infrastructure for the system. It includes:

- **Kafka:**
  - Service to handle message streaming.
  - Exposes port `9092` for communication with producers and consumers.

- **Zookeeper:**
  - Service to manage Kafka's metadata.
  - Exposes port `2181`.

- **Elasticsearch:**
  - Service to store and index anomalies.
  - Exposes port `9200` for API access.

- **Kibana:**
  - Service to visualize the indexed data.
  - Exposes port `5601` for dashboard access.

**Sample YAML Configuration:**

```yaml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.9.1
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

---

## **Features**

### **FHIR Compliance**

- Blood pressure data is structured in FHIR JSON format, including:
  - `resourceType` (e.g., Observation).
  - `component` (e.g., systolic and diastolic pressure values).
  - `status` and `category` fields.

### **Data Classification**

- **Normal Observations:**
  - Systolic < 120 and Diastolic < 80.
  - Saved in `normal_observations.json`.
- **Anomalies:**
  - Elevated, Hypertension Stage 1, Hypertension Stage 2, or Hypertensive Crisis.
  - Indexed into Elasticsearch (`bp_fhir_index`).


---

## **File Structure**

```
project-directory/
├── docker-compose.yml        # Docker configuration for Kafka, Elasticsearch, and Kibana
├── requirements.txt          # Python dependencies
├── src/
│   ├── kafka_producer.py     # Kafka producer script
│   ├── kafka_consumer.py     # Kafka consumer script
│   └── normal_observations.json  # File storing normal observations
└── README.md                 # Project documentation
```

---

## **Troubleshooting**

1. **Kafka Connection Issues:**

   - Ensure Kafka is running and reachable at `localhost:9092`.
   - Verify the topic `fhir_observations` exists.

2. **Elasticsearch Not Indexing:**

   - Ensure Elasticsearch is running and reachable at `localhost:9200`.
   - Check if the `bp_fhir_index` exists using:
     ```bash
     curl http://localhost:9200/_cat/indices?v
     ```

3. **Kibana Not Loading:**

   - Ensure Kibana is running and accessible at `http://localhost:5601`.

---

## **Future Improvements**

- Add real-time alerts for critical observations using Kibana Rules.
- Integrate additional health metrics (e.g., heart rate).
- Implement data encryption for secure transmission.

